{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfRt7KzW6ECC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, ResGatedGraphConv, TAGConv, ARMAConv, MFConv, global_mean_pool, BatchNorm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VU_jhxxPucAk",
    "outputId": "29121ea4-b235-4200-c075-c21fabe3de5b"
   },
   "outputs": [],
   "source": [
    "X = np.load(\".../data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmsJLSPFvXs2",
    "outputId": "cebd8e92-574a-4641-978d-9a5f8199b88e"
   },
   "outputs": [],
   "source": [
    "labels = np.load(\".../labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXvO1b-yyv-X"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "X = torch.tensor(X).float()\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OH7JWJqUjK0"
   },
   "outputs": [],
   "source": [
    "# LSTM network for feature extraction\n",
    "class Featurizer(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Featurizer, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, embedding_dim, batch_first=True)\n",
    "        self.project = nn.Linear(embedding_dim, 3)\n",
    "        self.project.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if type(x) in [nn.Linear, nn.LSTM] else None)\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return h, F.softmax(self.project(h), dim=-1).squeeze(0)\n",
    "    \n",
    "# Basic architecture of our GCNN\n",
    "\n",
    "class EEGraph(nn.Module):\n",
    "    def __init__(self, embedding_dim, first_conv, n_layers, conv_layer):\n",
    "        super(EEGraph, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.convs = []\n",
    "        self.bns = []\n",
    "        d_in = embedding_dim\n",
    "        d_out = first_conv\n",
    "        for i in range(n_layers):\n",
    "            self.convs.append(conv_layer(d_in, d_out))\n",
    "            self.bns.append(BatchNorm(d_out, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True))\n",
    "            if i < n_layers - 1:\n",
    "                d_in, d_out = d_out, 2*d_out\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList(self.convs)\n",
    "        self.bns = torch.nn.ModuleList(self.bns)\n",
    "        self.project = nn.Linear(d_out, 3) \n",
    "    \n",
    "        self.project.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if type(x) == nn.Linear else None)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, (conv, bn) in enumerate(zip(self.convs, self.bns)):\n",
    "            x = conv(x, edge_index).permute(0, 2, 1)\n",
    "            x = bn(x)\n",
    "            x = F.dropout(F.leaky_relu(x, negative_slope=0.01), p=0.5, training=self.training).permute(0, 2, 1)\n",
    "        out = x.mean(dim=1).squeeze(dim=-1)\n",
    "        out = self.project(out)\n",
    "        return F.softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDYXutZVUqp3"
   },
   "outputs": [],
   "source": [
    "# Here we extract the embeddings features of the LSTM network for each electrode\n",
    "def get_embeddings(X, labels, channel, embedding_dim, n_epochs=10, lr=0.1):\n",
    "    m = Featurizer(embedding_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "    for epoch in range(n_epochs):\n",
    "        indices = torch.randperm(15*3*15)\n",
    "        acc_loss = 0.\n",
    "        for j, batch in enumerate(indices.view(-1, 15)):\n",
    "            optimizer.zero_grad()\n",
    "            embeddings, outputs = m(X[batch, channel:channel+1, :].permute(0, 2, 1))\n",
    "            acc = (torch.argmax(outputs, dim=-1) == labels[batch]).float().sum() / len(outputs)\n",
    "            loss = criterion(outputs, labels[batch])\n",
    "            loss.backward()\n",
    "            acc_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        if epoch % 5 == 4:\n",
    "            print(\"Dim\", embedding_dim, \"Channel:\", channel, \"Epoch:\", epoch, \"Loss:\", loss.item(), \"Accuracy\", acc_loss / 15)\n",
    "    return m(X[:, channel:channel+1, :].permute(0,2, 1))[0]\\\n",
    "            .detach().squeeze(0).unsqueeze(1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NktUHaVBUqsE",
    "outputId": "78ebe995-f5e1-4a4b-d1e9-0992a4e431b7"
   },
   "outputs": [],
   "source": [
    "#We extract features with dimensions 16,32 and 64\n",
    "for D in [16, 32, 64]:\n",
    "    embeddings = [get_embeddings(X, labels, i, embedding_dim=D, n_epochs=50) for i in range(X.shape[1])]\n",
    "    np.save(f\".../graph_{D}.npy\", np.concatenate(embeddings, axis=1))\n",
    "    del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NQniVapCO4g",
    "outputId": "7cdc1f70-0a7a-4d42-d774-c6024d5b90e7"
   },
   "outputs": [],
   "source": [
    "# The order of the channels based on dataset\n",
    "\n",
    "channel_order = \"\"\"\n",
    "FP1\n",
    "FPZ\n",
    "FP2\n",
    "AF3\n",
    "AF4\n",
    "F7\n",
    "F5\n",
    "F3\n",
    "F1\n",
    "FZ\n",
    "F2\n",
    "F4\n",
    "F6\n",
    "F8\n",
    "FT7\n",
    "FC5\n",
    "FC3\n",
    "FC1\n",
    "FCZ\n",
    "FC2\n",
    "FC4\n",
    "FC6\n",
    "FT8\n",
    "T7\n",
    "C5\n",
    "C3\n",
    "C1\n",
    "CZ\n",
    "C2\n",
    "C4\n",
    "C6\n",
    "T8\n",
    "TP7\n",
    "CP5\n",
    "CP3\n",
    "CP1\n",
    "CPZ\n",
    "CP2\n",
    "CP4\n",
    "CP6\n",
    "TP8\n",
    "P7\n",
    "P5\n",
    "P3\n",
    "P1\n",
    "PZ\n",
    "P2\n",
    "P4\n",
    "P6\n",
    "P8\n",
    "PO7\n",
    "PO5\n",
    "PO3\n",
    "POZ\n",
    "PO4\n",
    "PO6\n",
    "PO8\n",
    "CB1\n",
    "O1\n",
    "OZ\n",
    "O2\n",
    "CB2\n",
    "\"\"\".split('\\n')[1:]\n",
    "channel_order[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDFd1qvzCsYD"
   },
   "outputs": [],
   "source": [
    "# Define the edges between the electrodes\n",
    "\n",
    "edges = [['O2', 'CB2'],\n",
    " ['O2', 'OZ'],\n",
    " ['O1', 'OZ'],\n",
    " ['O1', 'CB1'],\n",
    " ['PO8', 'P8'],\n",
    " ['PO8', 'CB2'],\n",
    " ['PO6', 'PO4'],\n",
    " ['PO6', 'PO8'],\n",
    " ['PO6', 'P6'],\n",
    " ['PO6', 'CB2'],\n",
    " ['PO4', 'P2'],\n",
    " ['PO4', 'O2'],\n",
    " ['POZ', 'PZ'],\n",
    " ['POZ', 'PO3'],\n",
    " ['POZ', 'PO4'],\n",
    " ['POZ', 'OZ'],\n",
    " ['PO3', 'P1'],\n",
    " ['PO3', 'PO5'],\n",
    " ['PO3', 'O1'],\n",
    " ['PO5', 'CB1'],\n",
    " ['PO7', 'P7'],\n",
    " ['PO7', 'PO5'],\n",
    " ['PO7', 'CB1'],\n",
    " ['P4', 'CP4'],\n",
    " ['P4', 'P2'],\n",
    " ['P4', 'P6'],\n",
    " ['P2', 'CP2'],\n",
    " ['PZ', 'P1'],\n",
    " ['PZ', 'P2'],\n",
    " ['P5', 'P7'],\n",
    " ['P5', 'P3'],\n",
    " ['P5', 'PO5'],\n",
    " ['P1', 'P3'],\n",
    " ['P6', 'CP6'],\n",
    " ['P6', 'P8'],\n",
    " ['CP4', 'CP6'],\n",
    " ['CP4', 'CP2'],\n",
    " ['CPZ', 'CP2'],\n",
    " ['CPZ', 'PZ'],\n",
    " ['CPZ', 'CZ'],\n",
    " ['TP7', 'T7'],\n",
    " ['TP7', 'P7'],\n",
    " ['CP5', 'CP3'],\n",
    " ['CP5', 'TP7'],\n",
    " ['CP5', 'P5'],\n",
    " ['CP5', 'C5'],\n",
    " ['CP1', 'CPZ'],\n",
    " ['CP1', 'CP3'],\n",
    " ['CP1', 'P1'],\n",
    " ['CP1', 'C1'],\n",
    " ['CP3', 'P3'],\n",
    " ['CP3', 'C3'],\n",
    " ['TP8', 'CP6'],\n",
    " ['TP8', 'P8'],\n",
    " ['TP8', 'T8'],\n",
    " ['C4', 'CP4'],\n",
    " ['C2', 'C4'],\n",
    " ['C2', 'CZ'],\n",
    " ['C2', 'CP2'],\n",
    " ['C2', 'FC2'],\n",
    " ['CZ', 'C1'],\n",
    " ['C5', 'T7'],\n",
    " ['C3', 'C1'],\n",
    " ['C3', 'C5'],\n",
    " ['C3', 'FC3'],\n",
    " ['C6', 'C4'],\n",
    " ['C6', 'T8'],\n",
    " ['C6', 'CP6'],\n",
    " ['C6', 'FC6'],\n",
    " ['FC4', 'FC2'],\n",
    " ['FC4', 'F4'],\n",
    " ['FC4', 'C4'],\n",
    " ['FCZ', 'FC2'],\n",
    " ['FCZ', 'FC1'],\n",
    " ['FCZ', 'CZ'],\n",
    " ['FT7', 'F7'],\n",
    " ['FT7', 'T7'],\n",
    " ['FC5', 'FC3'],\n",
    " ['FC5', 'FT7'],\n",
    " ['FC5', 'C5'],\n",
    " ['FC5', 'F5'],\n",
    " ['FC1', 'FC3'],\n",
    " ['FC1', 'C1'],\n",
    " ['FT8', 'T8'],\n",
    " ['FC6', 'FC4'],\n",
    " ['FC6', 'FT8'],\n",
    " ['FC6', 'F6'],\n",
    " ['F5', 'F3'],\n",
    " ['F5', 'F7'],\n",
    " ['F5', 'AF3'],\n",
    " ['F8', 'FT8'],\n",
    " ['F8', 'F6'],\n",
    " ['F6', 'AF4'],\n",
    " ['F4', 'F6'],\n",
    " ['F4', 'AF4'],\n",
    " ['F2', 'FC2'],\n",
    " ['F2', 'F4'],\n",
    " ['F2', 'AF4'],\n",
    " ['FZ', 'FCZ'],\n",
    " ['FZ', 'F2'],\n",
    " ['FZ', 'F1'],\n",
    " ['F1', 'FC1'],\n",
    " ['F1', 'F3'],\n",
    " ['F1', 'AF3'],\n",
    " ['F3', 'FC3'],\n",
    " ['AF4', 'FP2'],\n",
    " ['AF3', 'F3'],\n",
    " ['AF3', 'FP1'],\n",
    " ['FPZ', 'FP1'],\n",
    " ['FPZ', 'FP2'],\n",
    " ['CB2', 'O2'],\n",
    " ['OZ', 'O2'],\n",
    " ['OZ', 'O1'],\n",
    " ['CB1', 'O1'],\n",
    " ['P8', 'PO8'],\n",
    " ['CB2', 'PO8'],\n",
    " ['PO4', 'PO6'],\n",
    " ['PO8', 'PO6'],\n",
    " ['P6', 'PO6'],\n",
    " ['CB2', 'PO6'],\n",
    " ['P2', 'PO4'],\n",
    " ['O2', 'PO4'],\n",
    " ['PZ', 'POZ'],\n",
    " ['PO3', 'POZ'],\n",
    " ['PO4', 'POZ'],\n",
    " ['OZ', 'POZ'],\n",
    " ['P1', 'PO3'],\n",
    " ['PO5', 'PO3'],\n",
    " ['O1', 'PO3'],\n",
    " ['CB1', 'PO5'],\n",
    " ['P7', 'PO7'],\n",
    " ['PO5', 'PO7'],\n",
    " ['CB1', 'PO7'],\n",
    " ['CP4', 'P4'],\n",
    " ['P2', 'P4'],\n",
    " ['P6', 'P4'],\n",
    " ['CP2', 'P2'],\n",
    " ['P1', 'PZ'],\n",
    " ['P2', 'PZ'],\n",
    " ['P7', 'P5'],\n",
    " ['P3', 'P5'],\n",
    " ['PO5', 'P5'],\n",
    " ['P3', 'P1'],\n",
    " ['CP6', 'P6'],\n",
    " ['P8', 'P6'],\n",
    " ['CP6', 'CP4'],\n",
    " ['CP2', 'CP4'],\n",
    " ['CP2', 'CPZ'],\n",
    " ['PZ', 'CPZ'],\n",
    " ['CZ', 'CPZ'],\n",
    " ['T7', 'TP7'],\n",
    " ['P7', 'TP7'],\n",
    " ['CP3', 'CP5'],\n",
    " ['TP7', 'CP5'],\n",
    " ['P5', 'CP5'],\n",
    " ['C5', 'CP5'],\n",
    " ['CPZ', 'CP1'],\n",
    " ['CP3', 'CP1'],\n",
    " ['P1', 'CP1'],\n",
    " ['C1', 'CP1'],\n",
    " ['P3', 'CP3'],\n",
    " ['C3', 'CP3'],\n",
    " ['CP6', 'TP8'],\n",
    " ['P8', 'TP8'],\n",
    " ['T8', 'TP8'],\n",
    " ['CP4', 'C4'],\n",
    " ['C4', 'C2'],\n",
    " ['CZ', 'C2'],\n",
    " ['CP2', 'C2'],\n",
    " ['FC2', 'C2'],\n",
    " ['C1', 'CZ'],\n",
    " ['T7', 'C5'],\n",
    " ['C1', 'C3'],\n",
    " ['C5', 'C3'],\n",
    " ['FC3', 'C3'],\n",
    " ['C4', 'C6'],\n",
    " ['T8', 'C6'],\n",
    " ['CP6', 'C6'],\n",
    " ['FC6', 'C6'],\n",
    " ['FC2', 'FC4'],\n",
    " ['F4', 'FC4'],\n",
    " ['C4', 'FC4'],\n",
    " ['FC2', 'FCZ'],\n",
    " ['FC1', 'FCZ'],\n",
    " ['CZ', 'FCZ'],\n",
    " ['F7', 'FT7'],\n",
    " ['T7', 'FT7'],\n",
    " ['FC3', 'FC5'],\n",
    " ['FT7', 'FC5'],\n",
    " ['C5', 'FC5'],\n",
    " ['F5', 'FC5'],\n",
    " ['FC3', 'FC1'],\n",
    " ['C1', 'FC1'],\n",
    " ['T8', 'FT8'],\n",
    " ['FC4', 'FC6'],\n",
    " ['FT8', 'FC6'],\n",
    " ['F6', 'FC6'],\n",
    " ['F3', 'F5'],\n",
    " ['F7', 'F5'],\n",
    " ['AF3', 'F5'],\n",
    " ['FT8', 'F8'],\n",
    " ['F6', 'F8'],\n",
    " ['AF4', 'F6'],\n",
    " ['F6', 'F4'],\n",
    " ['AF4', 'F4'],\n",
    " ['FC2', 'F2'],\n",
    " ['F4', 'F2'],\n",
    " ['AF4', 'F2'],\n",
    " ['FCZ', 'FZ'],\n",
    " ['F2', 'FZ'],\n",
    " ['F1', 'FZ'],\n",
    " ['FC1', 'F1'],\n",
    " ['F3', 'F1'],\n",
    " ['AF3', 'F1'],\n",
    " ['FC3', 'F3'],\n",
    " ['FP2', 'AF4'],\n",
    " ['F3', 'AF3'],\n",
    " ['FP1', 'AF3'],\n",
    " ['FP1', 'FPZ'],\n",
    " ['FP2', 'FPZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqnIJmTVUbU_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "connectivity = [[channel_order.index(e[0]), channel_order.index(e[1])] for e in edges]\n",
    "connectivity = torch.tensor(connectivity).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bgcaRGKUquM",
    "outputId": "3c0ebecf-da7c-4ee0-df18-976d6b9109e6"
   },
   "outputs": [],
   "source": [
    "best_f1_score = -1\n",
    "best_trial_name = None\n",
    "n_epochs = 500\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "batch_size = 54\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for node_dim in [16, 32, 64]:\n",
    "    node_features = np.load(f\".../graph_{node_dim}.npy\")\n",
    "    A, Xte, yA, yte = train_test_split(node_features, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=0)\n",
    "    Xtr, Xtr_valid, ytr, ytr_valid = train_test_split(A, yA, test_size=0.2, shuffle=True, stratify=yA, random_state=0)\n",
    "    Xtr = torch.tensor(Xtr).float()\n",
    "    Xtr_valid = torch.tensor(Xtr_valid).float()\n",
    "    Xte = torch.tensor(Xte).float()\n",
    "    ytr = torch.tensor(ytr)\n",
    "    ytr_valid = torch.tensor(ytr_valid)\n",
    "    yte = torch.tensor(yte)\n",
    "    for conv_fn in [TAGConv, ARMAConv, MFConv, GCNConv, SAGEConv, ResGatedGraphConv]:\n",
    "        for n_layers in range(1, 4):\n",
    "            for conv_dim in [32, 64, 128, 256]:\n",
    "                trial_name = f\"node_dim_{node_dim}-conv_fn_{conv_fn.__name__}-conv_layers_{n_layers}-conv_dim_{conv_dim}\"\n",
    "                print(f\"@: {trial_name}\")\n",
    "                model = EEGraph(embedding_dim=Xtr.shape[-1], \n",
    "                        first_conv=conv_dim,\n",
    "                        n_layers=n_layers,\n",
    "                        conv_layer=conv_fn)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "                for epoch in range(n_epochs):\n",
    "                    model.train()\n",
    "                    indices = torch.randperm(len(Xtr))\n",
    "                    for j, batch in enumerate(indices.view(-1, 54)):\n",
    "                        optimizer.zero_grad()\n",
    "                        batch_input = Xtr[batch]\n",
    "                        outputs = model(batch_input, connectivity)\n",
    "                        loss = criterion(outputs, ytr[batch])\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                with torch.no_grad() :\n",
    "                    model.eval()\n",
    "                    outputs = model(Xtr_valid, connectivity)\n",
    "                    output_classes = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
    "                    f1 = f1_score(ytr_valid, output_classes, average=\"macro\")\n",
    "                    if f1 > best_f1_score:\n",
    "                        best_trial_name = trial_name\n",
    "                        best_f1_score = f1\n",
    "                        print(\"-\"*100)\n",
    "                        print(f\"Best model so far: {best_trial_name}\")\n",
    "                        print(f\"Best F1 Score: %{100*best_f1_score:.2f}\")\n",
    "                        test_outputs = model(Xte, connectivity)\n",
    "                        test_output_classes = torch.argmax(test_outputs, dim=-1).cpu().numpy()\n",
    "                        print(classification_report(yte, test_output_classes, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
    "                        print(\"-\"*100)\n",
    "                        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv5asXLsWZcz",
    "outputId": "ab864c10-b9a2-4751-aae8-5e7bdb7436ab"
   },
   "outputs": [],
   "source": [
    "node_dim = ... # The best parameter that you get from the previous cell\n",
    "conv_fn = ... # The best parameter that you get from the previous cell\n",
    "n_layers = ... # The best parameter that you get from the previous cell\n",
    "conv_dim = ... # The best parameter that you get from the previous cell\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "n_epochs = 500\n",
    "node_features = np.load(f\".../graph_{node_dim}.npy\")\n",
    "Xtr, Xte, ytr, yte = train_test_split(node_features, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=0)\n",
    "model = EEGraph(embedding_dim=Xtr.shape[-1], \n",
    "                        first_conv=conv_dim,\n",
    "                        n_layers=n_layers,\n",
    "                        conv_layer=conv_fn)\n",
    "Xtr = torch.tensor(Xtr).float()\n",
    "Xte = torch.tensor(Xte).float()\n",
    "ytr = torch.tensor(ytr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_f1_score = -1\n",
    "best_acc = -1\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    indices = torch.randperm(len(Xtr))\n",
    "    for j, batch in enumerate(indices.view(-1, 54)):\n",
    "        optimizer.zero_grad()\n",
    "        batch_input = Xtr[batch]\n",
    "        outputs = model(batch_input, connectivity)\n",
    "        loss = criterion(outputs, ytr[batch])\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(Xte, connectivity)\n",
    "        output_classes = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
    "        f1 = f1_score(yte, output_classes, average=\"macro\") \n",
    "        if f1 > best_f1_score:\n",
    "            acc = accuracy_score(yte, output_classes)\n",
    "            best_f1_score = f1\n",
    "            print(\"-\"*100)\n",
    "            print(f\"Best F1 Score: %{100*best_f1_score:.2f}\")\n",
    "            print(classification_report(yte, output_classes, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
    "            print(\"-\"*100)\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "graph_eeg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
